{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d139947",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a4306ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json, warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import ElasticNet, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2e9d93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/dataset/processed/preprocessed_data.csv\n"
     ]
    }
   ],
   "source": [
    "path = Path.cwd().parent / \"dataset\" /\"processed\" /\"preprocessed_data.csv\"\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ba84547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OrderID</th>\n",
       "      <th>OrderDate</th>\n",
       "      <th>ShipDate</th>\n",
       "      <th>ShipMode</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>CustomerName</th>\n",
       "      <th>Segment</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>Region</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Sales</th>\n",
       "      <th>DaysToShip</th>\n",
       "      <th>OrderYear</th>\n",
       "      <th>OrderMonth</th>\n",
       "      <th>OrderQuarter</th>\n",
       "      <th>OrderYearMonth</th>\n",
       "      <th>OrderWeekOfYear</th>\n",
       "      <th>OrderMonthName</th>\n",
       "      <th>OrderIsWeekendOrder</th>\n",
       "      <th>ShipYear</th>\n",
       "      <th>ShipMonth</th>\n",
       "      <th>ShipQuarter</th>\n",
       "      <th>ShipYearMonth</th>\n",
       "      <th>ShipWeekOfYear</th>\n",
       "      <th>ShipMonthName</th>\n",
       "      <th>ShipIsWeekendShip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ca-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>second class</td>\n",
       "      <td>cg-12520</td>\n",
       "      <td>claire gute</td>\n",
       "      <td>consumer</td>\n",
       "      <td>united states</td>\n",
       "      <td>henderson</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>42420</td>\n",
       "      <td>south</td>\n",
       "      <td>FUR-BO-10001798</td>\n",
       "      <td>furniture</td>\n",
       "      <td>bookcases</td>\n",
       "      <td>bush somerset collection bookcase</td>\n",
       "      <td>261.9600</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>45</td>\n",
       "      <td>November</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>45</td>\n",
       "      <td>November</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ca-2017-152156</td>\n",
       "      <td>2017-11-08</td>\n",
       "      <td>2017-11-11</td>\n",
       "      <td>second class</td>\n",
       "      <td>cg-12520</td>\n",
       "      <td>claire gute</td>\n",
       "      <td>consumer</td>\n",
       "      <td>united states</td>\n",
       "      <td>henderson</td>\n",
       "      <td>kentucky</td>\n",
       "      <td>42420</td>\n",
       "      <td>south</td>\n",
       "      <td>FUR-CH-10000454</td>\n",
       "      <td>furniture</td>\n",
       "      <td>chairs</td>\n",
       "      <td>hon deluxe fabric upholstered stacking chairs,...</td>\n",
       "      <td>731.9400</td>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>45</td>\n",
       "      <td>November</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-11</td>\n",
       "      <td>45</td>\n",
       "      <td>November</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ca-2017-138688</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>second class</td>\n",
       "      <td>dv-13045</td>\n",
       "      <td>darrin van huff</td>\n",
       "      <td>corporate</td>\n",
       "      <td>united states</td>\n",
       "      <td>los angeles</td>\n",
       "      <td>california</td>\n",
       "      <td>90036</td>\n",
       "      <td>west</td>\n",
       "      <td>OFF-LA-10000240</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>labels</td>\n",
       "      <td>self-adhesive address labels for typewriters b...</td>\n",
       "      <td>14.6200</td>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>24</td>\n",
       "      <td>June</td>\n",
       "      <td>False</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>24</td>\n",
       "      <td>June</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>us-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>standard class</td>\n",
       "      <td>so-20335</td>\n",
       "      <td>sean o'donnell</td>\n",
       "      <td>consumer</td>\n",
       "      <td>united states</td>\n",
       "      <td>fort lauderdale</td>\n",
       "      <td>florida</td>\n",
       "      <td>33311</td>\n",
       "      <td>south</td>\n",
       "      <td>FUR-TA-10000577</td>\n",
       "      <td>furniture</td>\n",
       "      <td>tables</td>\n",
       "      <td>bretford cr4500 series slim rectangular table</td>\n",
       "      <td>957.5775</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>41</td>\n",
       "      <td>October</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>42</td>\n",
       "      <td>October</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us-2016-108966</td>\n",
       "      <td>2016-10-11</td>\n",
       "      <td>2016-10-18</td>\n",
       "      <td>standard class</td>\n",
       "      <td>so-20335</td>\n",
       "      <td>sean o'donnell</td>\n",
       "      <td>consumer</td>\n",
       "      <td>united states</td>\n",
       "      <td>fort lauderdale</td>\n",
       "      <td>florida</td>\n",
       "      <td>33311</td>\n",
       "      <td>south</td>\n",
       "      <td>OFF-ST-10000760</td>\n",
       "      <td>office supplies</td>\n",
       "      <td>storage</td>\n",
       "      <td>eldon fold 'n roll cart system</td>\n",
       "      <td>22.3680</td>\n",
       "      <td>7</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>41</td>\n",
       "      <td>October</td>\n",
       "      <td>False</td>\n",
       "      <td>2016</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>42</td>\n",
       "      <td>October</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          OrderID   OrderDate    ShipDate        ShipMode CustomerID  \\\n",
       "0  ca-2017-152156  2017-11-08  2017-11-11    second class   cg-12520   \n",
       "1  ca-2017-152156  2017-11-08  2017-11-11    second class   cg-12520   \n",
       "2  ca-2017-138688  2017-06-12  2017-06-16    second class   dv-13045   \n",
       "3  us-2016-108966  2016-10-11  2016-10-18  standard class   so-20335   \n",
       "4  us-2016-108966  2016-10-11  2016-10-18  standard class   so-20335   \n",
       "\n",
       "      CustomerName    Segment        Country             City       State  \\\n",
       "0      claire gute   consumer  united states        henderson    kentucky   \n",
       "1      claire gute   consumer  united states        henderson    kentucky   \n",
       "2  darrin van huff  corporate  united states      los angeles  california   \n",
       "3   sean o'donnell   consumer  united states  fort lauderdale     florida   \n",
       "4   sean o'donnell   consumer  united states  fort lauderdale     florida   \n",
       "\n",
       "   PostalCode Region        ProductID         Category SubCategory  \\\n",
       "0       42420  south  FUR-BO-10001798        furniture   bookcases   \n",
       "1       42420  south  FUR-CH-10000454        furniture      chairs   \n",
       "2       90036   west  OFF-LA-10000240  office supplies      labels   \n",
       "3       33311  south  FUR-TA-10000577        furniture      tables   \n",
       "4       33311  south  OFF-ST-10000760  office supplies     storage   \n",
       "\n",
       "                                         ProductName     Sales  DaysToShip  \\\n",
       "0                  bush somerset collection bookcase  261.9600           3   \n",
       "1  hon deluxe fabric upholstered stacking chairs,...  731.9400           3   \n",
       "2  self-adhesive address labels for typewriters b...   14.6200           4   \n",
       "3      bretford cr4500 series slim rectangular table  957.5775           7   \n",
       "4                     eldon fold 'n roll cart system   22.3680           7   \n",
       "\n",
       "   OrderYear  OrderMonth  OrderQuarter OrderYearMonth  OrderWeekOfYear  \\\n",
       "0       2017          11             4        2017-11               45   \n",
       "1       2017          11             4        2017-11               45   \n",
       "2       2017           6             2        2017-06               24   \n",
       "3       2016          10             4        2016-10               41   \n",
       "4       2016          10             4        2016-10               41   \n",
       "\n",
       "  OrderMonthName  OrderIsWeekendOrder  ShipYear  ShipMonth  ShipQuarter  \\\n",
       "0       November                False      2017         11            4   \n",
       "1       November                False      2017         11            4   \n",
       "2           June                False      2017          6            2   \n",
       "3        October                False      2016         10            4   \n",
       "4        October                False      2016         10            4   \n",
       "\n",
       "  ShipYearMonth  ShipWeekOfYear ShipMonthName  ShipIsWeekendShip  \n",
       "0       2017-11              45      November               True  \n",
       "1       2017-11              45      November               True  \n",
       "2       2017-06              24          June              False  \n",
       "3       2016-10              42       October              False  \n",
       "4       2016-10              42       October              False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base = pd.read_csv(path)\n",
    "df = df_base\n",
    "pd.set_option(\"display.max_column\",None)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47eedb94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['OrderID', 'OrderDate', 'ShipDate', 'ShipMode', 'CustomerID',\n",
      "       'CustomerName', 'Segment', 'Country', 'City', 'State', 'PostalCode',\n",
      "       'Region', 'ProductID', 'Category', 'SubCategory', 'ProductName',\n",
      "       'Sales', 'DaysToShip', 'OrderYear', 'OrderMonth', 'OrderQuarter',\n",
      "       'OrderYearMonth', 'OrderWeekOfYear', 'OrderMonthName',\n",
      "       'OrderIsWeekendOrder', 'ShipYear', 'ShipMonth', 'ShipQuarter',\n",
      "       'ShipYearMonth', 'ShipWeekOfYear', 'ShipMonthName',\n",
      "       'ShipIsWeekendShip'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option(\"display.max_row\",None)\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19cce009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The .env file is loaded successfully.\n",
      "Using SQL_SERVER   = sqlsrv-retail-dev.database.windows.net\n",
      "Using SQL_DATABASE = sqldb-dretail-dev\n",
      "Using SQL_USERNAME = sqladmin\n",
      "DRIVER=/opt/homebrew/lib/libmsodbcsql.18.dylib;SERVER=sqlsrv-retail-dev.database.windows.net;DATABASE=sqldb-dretail-dev;UID=sqladmin;PWD=HASEEBSAGHEER12!@;Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\n",
      "mssql+pyodbc:///?odbc_connect=DRIVER%3D%2Fopt%2Fhomebrew%2Flib%2Flibmsodbcsql.18.dylib%3BSERVER%3Dsqlsrv-retail-dev.database.windows.net%3BDATABASE%3Dsqldb-dretail-dev%3BUID%3Dsqladmin%3BPWD%3DHASEEBSAGHEER12%21%40%3BEncrypt%3Dyes%3BTrustServerCertificate%3Dno%3BConnection+Timeout%3D30%3B\n",
      "SQLAlchemy engine created successfully.\n",
      "Testing connection...\n",
      "Query returned 10 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DOTENV_PATH = \"/Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/secrets/.env\"\n",
    "\n",
    "# Force .env to override anything already in the process\n",
    "if load_dotenv(dotenv_path=DOTENV_PATH, override=True):\n",
    "    print(\"The .env file is loaded successfully.\")\n",
    "else:\n",
    "    print(\"Warning: .env not found or could not be loaded.\")\n",
    "\n",
    "#This block of code will verify the SQL server login credentials\n",
    "server   = os.getenv(\"SQL_SERVER\")\n",
    "database = os.getenv(\"SQL_DATABASE\")\n",
    "username = os.getenv(\"SQL_USERNAME\")\n",
    "password = os.getenv(\"SQL_PASSWORD\")\n",
    "print(\"Using SQL_SERVER   =\", server)\n",
    "print(\"Using SQL_DATABASE =\", database)\n",
    "print(\"Using SQL_USERNAME =\", username)\n",
    "\n",
    "if not all([server, database, username, password]):\n",
    "    print(\"ERROR: Missing one or more of SQL_SERVER / SQL_DATABASE / SQL_USERNAME / SQL_PASSWORD\")\n",
    "\n",
    "DRIVER_PATH = \"/opt/homebrew/lib/libmsodbcsql.18.dylib\"\n",
    "\n",
    "#Preparing the credentials for logging in the account (azure SQL Server)\n",
    "odbc = (\n",
    "    f\"DRIVER={DRIVER_PATH};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    f\"UID={username};\"\n",
    "    f\"PWD={password};\"\n",
    "    \"Encrypt=yes;\"\n",
    "    \"TrustServerCertificate=no;\"\n",
    "    \"Connection Timeout=30;\"\n",
    ")\n",
    "print(odbc)\n",
    "\n",
    "conn_url = f\"mssql+pyodbc:///?odbc_connect={quote_plus(odbc)}\"\n",
    "print(conn_url)\n",
    "try:\n",
    "    engine = create_engine(conn_url, fast_executemany=True)\n",
    "    print(\"SQLAlchemy engine created successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Error creating engine:\", e)\n",
    "\n",
    "\n",
    "try:\n",
    "    print(\"Testing connection...\")\n",
    "    with engine.connect() as conn:\n",
    "        df = pd.read_sql(\"SELECT TOP 10 * FROM dbo.stg_sales;\", conn)\n",
    "        if df.empty:\n",
    "            print(\"Query returned 0 rows.\")\n",
    "        else:\n",
    "            print(f\"Query returned {len(df)} rows\")\n",
    "            \n",
    "\n",
    "except:\n",
    "    print(\"There was something wrong in getting data from Azure SQl Server\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f2b9f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Day 4: Local Modeling (No Azure writes)\n",
    "# - Reuse YOUR working SQLAlchemy engine (no ODBC setup)\n",
    "# - Read from SQL (or local fallback), train models, save artifacts locally\n",
    "# =========================\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths, folders, env\n",
    "# ----------------------------\n",
    "# Use your exact .env path (we won't rely on it for the engine, but it's handy to keep things tidy)\n",
    "ENV_PATH = r\"/Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/secrets/.env\"\n",
    "load_dotenv(dotenv_path=ENV_PATH)\n",
    "\n",
    "ROOT = os.getcwd()\n",
    "ARTIF_DIR   = os.path.join(ROOT, \"models\")\n",
    "REPORTS_DIR = os.path.join(ROOT, \"reports\")\n",
    "INPUTS_DIR  = os.path.join(ROOT, \"_inputs\")   # optional local fallback\n",
    "os.makedirs(ARTIF_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "os.makedirs(INPUTS_DIR, exist_ok=True)\n",
    "\n",
    "STAMP = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adca226c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine exist mssql\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 1) Create engine (PASTE YOUR WORKING CODE HERE)\n",
    "# ----------------------------\n",
    "# IMPORTANT:\n",
    "# Paste the SAME engine creation code that worked in your “alternate method” script.\n",
    "# Example placeholders (DO NOT use unless they are what you used and tested):\n",
    "#   from sqlalchemy import create_engine\n",
    "#   engine = create_engine(\"mssql+pytds://sqladmin:YOURPWD@sqlsrv-retail-dev.database.windows.net:1433/sqldb-retail-dev\")\n",
    "#\n",
    "# Or whatever you used that successfully connected.\n",
    "#\n",
    "# After pasting, you should have: engine  (a working SQLAlchemy engine)\n",
    "\n",
    "# === START: your engine code ===\n",
    "# engine = <YOUR WORKING ENGINE HERE>\n",
    "# === END: your engine code ===\n",
    "\n",
    "try:\n",
    "    if engine.name:\n",
    "        print(f\"Engine exist {engine.name}\")\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Please paste your working `engine = ...` code in the cell above before running.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cebbdc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded shape: (9788, 7)\n",
      "          OrderID CustomerID        ProductID Region  OrderDate   ShipDate  \\\n",
      "0  ca-2017-152156   cg-12520  FUR-BO-10001798  south 2017-11-08 2017-11-11   \n",
      "1  ca-2017-152156   cg-12520  FUR-CH-10000454  south 2017-11-08 2017-11-11   \n",
      "2  ca-2017-138688   dv-13045  OFF-LA-10000240   west 2017-06-12 2017-06-16   \n",
      "\n",
      "    Sales  \n",
      "0  261.96  \n",
      "1  731.94  \n",
      "2   14.62  \n"
     ]
    }
   ],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "def read_from_sql_or_fallback():\n",
    "    \"\"\"\n",
    "    Try reading from SQL using YOUR working engine.\n",
    "    Prefer view dbo.v_processed_sales (if present), else fallback to fact_sales minimal cols.\n",
    "    If SQL fails or returns empty, fallback to local files in ./_inputs/.\n",
    "    \"\"\"\n",
    "    # 2a) Try SQL\n",
    "    try:\n",
    "        with engine.begin() as conn:\n",
    "            has_view = False\n",
    "            try:\n",
    "                _ = pd.read_sql(\"SELECT TOP (1) * FROM dbo.facts_sales\", conn)\n",
    "                has_view = True\n",
    "            except Exception:\n",
    "                has_view = False\n",
    "\n",
    "            if has_view:\n",
    "                df = pd.read_sql(\"SELECT * FROM dbo.facts_sales\", conn)\n",
    "            else:\n",
    "                q = \"\"\"\n",
    "                SELECT\n",
    "                  f.OrderID, f.CustomerID, f.ProductID, f.Region,\n",
    "                  f.OrderDate, f.ShipDate, f.Sales\n",
    "                FROM dbo.fact_sales f\n",
    "                \"\"\"\n",
    "                df = pd.read_sql(q, conn)\n",
    "        if not df.empty:\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        print(\"SQL read failed, will try local fallback:\", repr(e))\n",
    "\n",
    "    # 2b) Fallback to local\n",
    "    parquet_path = os.path.join(INPUTS_DIR, \"processed_sales.parquet\")\n",
    "    csv_path     = os.path.join(INPUTS_DIR, \"fact_sales.csv\")\n",
    "\n",
    "    if os.path.exists(parquet_path):\n",
    "        print(\"Loading local:\", parquet_path)\n",
    "        return pd.read_parquet(parquet_path)\n",
    "    if os.path.exists(csv_path):\n",
    "        print(\"Loading local:\", csv_path)\n",
    "        return pd.read_csv(csv_path)\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not read from SQL and no local fallback found.\\n\"\n",
    "        \"Put a file at _inputs/processed_sales.parquet or _inputs/fact_sales.csv and rerun.\"\n",
    "    )\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Load data\n",
    "# ----------------------------\n",
    "df = read_from_sql_or_fallback()\n",
    "print(\"Loaded shape:\", df.shape)\n",
    "print(df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d7567f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post-clean shape: (9788, 21)\n"
     ]
    }
   ],
   "source": [
    "def to_datetime_safe(s):\n",
    "    return pd.to_datetime(s, errors='coerce', dayfirst=True)\n",
    "\n",
    "if 'OrderDate' in df.columns and not np.issubdtype(df['OrderDate'].dtype, np.datetime64):\n",
    "    df['OrderDate'] = to_datetime_safe(df['OrderDate'])\n",
    "if 'ShipDate' in df.columns and not np.issubdtype(df['ShipDate'].dtype, np.datetime64):\n",
    "    df['ShipDate'] = to_datetime_safe(df['ShipDate'])\n",
    "\n",
    "# Derived from OrderDate\n",
    "if 'OrderDate' in df.columns:\n",
    "    df['OrderYear'] = df['OrderDate'].dt.year\n",
    "    df['OrderMonth'] = df['OrderDate'].dt.month\n",
    "    df['OrderQuarter'] = df['OrderDate'].dt.quarter\n",
    "    df['OrderWeekOfYear'] = df['OrderDate'].dt.isocalendar().week.astype('Int64')\n",
    "    df['OrderMonthName'] = df['OrderDate'].dt.month_name()\n",
    "    df['OrderIsWeekendOrder'] = df['OrderDate'].dt.dayofweek.isin([5,6]).astype(int)\n",
    "    df['OrderYearMonth'] = df['OrderDate'].dt.to_period('M').astype(str)\n",
    "\n",
    "# Derived from ShipDate\n",
    "if 'ShipDate' in df.columns:\n",
    "    df['ShipYear'] = df['ShipDate'].dt.year\n",
    "    df['ShipMonth'] = df['ShipDate'].dt.month\n",
    "    df['ShipQuarter'] = df['ShipDate'].dt.quarter\n",
    "    df['ShipWeekOfYear'] = df['ShipDate'].dt.isocalendar().week.astype('Int64')\n",
    "    df['ShipMonthName'] = df['ShipDate'].dt.month_name()\n",
    "    try:\n",
    "        df['ShipIsWeekendShip'] = df['ShipDate'].dt.dayofweek.isin([5,6]).astype(int)\n",
    "    except Exception:\n",
    "        df['ShipIsWeekendShip'] = 0\n",
    "\n",
    "# DaysToShip\n",
    "if {'OrderDate','ShipDate'}.issubset(df.columns):\n",
    "    df['DaysToShip'] = (df['ShipDate'] - df['OrderDate']).dt.days\n",
    "\n",
    "# Clean strings for key categoricals\n",
    "for col in ['ShipMode','Segment','Country','State','Region','Category','SubCategory','ProductName','CustomerName','City','PostalCode']:\n",
    "    if col in df.columns and df[col].dtype == object:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Drop bad rows\n",
    "need_cols = [c for c in ['OrderID','ProductID','CustomerID','OrderDate','Sales'] if c in df.columns]\n",
    "df = df.dropna(subset=need_cols)\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], errors='coerce')\n",
    "df = df.dropna(subset=['Sales'])\n",
    "df = df[df['Sales'] >= 0]\n",
    "print(\"Post-clean shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b334029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cutoff: 2018-07-20 | Train: (7831, 7) | Test: (1957, 7)\n",
      "Categoricals: ['Region', 'OrderMonthName']\n",
      "Numerics: ['OrderYear', 'OrderMonth', 'OrderQuarter', 'OrderWeekOfYear', 'OrderIsWeekendOrder']\n"
     ]
    }
   ],
   "source": [
    "categorical_features = [\n",
    "    'ShipMode','Segment','Country','State','Region','Category','SubCategory','OrderMonthName'\n",
    "]\n",
    "numeric_features = [\n",
    "    'OrderYear','OrderMonth','OrderQuarter','OrderWeekOfYear','OrderIsWeekendOrder'\n",
    "]\n",
    "target_col = 'Sales'\n",
    "\n",
    "drop_cols = [\n",
    "    'CustomerName','City','PostalCode','ProductName',\n",
    "    'OrderID','CustomerID','ProductID',\n",
    "    'OrderDate','ShipDate',\n",
    "    'ShipYear','ShipMonth','ShipQuarter','ShipYearMonth','ShipWeekOfYear','ShipMonthName','ShipIsWeekendShip','DaysToShip',\n",
    "    'OrderYearMonth'\n",
    "]\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "\n",
    "X_all = df.drop(columns=[target_col] + drop_cols, errors='ignore')\n",
    "y_all = df[target_col].astype(float)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Time-aware split\n",
    "# ----------------------------\n",
    "cutoff = df['OrderDate'].quantile(0.80)\n",
    "train_mask = df['OrderDate'] <= cutoff\n",
    "X_train, y_train = X_all[train_mask].copy(), y_all[train_mask].copy()\n",
    "X_test,  y_test  = X_all[~train_mask].copy(), y_all[~train_mask].copy()\n",
    "\n",
    "print(\"Cutoff:\", cutoff.date(), \"| Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "cat_cols = [c for c in categorical_features if c in X_train.columns]\n",
    "num_cols = [c for c in numeric_features if c in X_train.columns]\n",
    "print(\"Categoricals:\", cat_cols)\n",
    "print(\"Numerics:\", num_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9f59afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REG elasticnet] MAE=264.15 | RMSE=591.51 | R2=-0.002\n",
      "[REG rf] MAE=290.38 | RMSE=624.65 | R2=-0.118\n",
      "[REG gbr] MAE=279.88 | RMSE=594.36 | R2=-0.012\n",
      "\n",
      "Best regression: elasticnet MAE= 264.15\n"
     ]
    }
   ],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), cat_cols),\n",
    "        (\"num\", Pipeline(steps=[(\"scale\", StandardScaler())]), num_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Regression (ElasticNet, RF, GBR)\n",
    "# ----------------------------\n",
    "reg_models = {\n",
    "    \"elasticnet\": ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42),\n",
    "    \"rf\": RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=42),\n",
    "    \"gbr\": GradientBoostingRegressor(random_state=42),\n",
    "}\n",
    "reg_results = {}\n",
    "best_reg_name, best_reg_pipe, best_mae = None, None, 1e18\n",
    "\n",
    "for name, est in reg_models.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", est)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    preds = pipe.predict(X_test)\n",
    "    mae  = mean_absolute_error(y_test, preds)\n",
    "    mse  = mean_squared_error(y_test, preds)\n",
    "    r2   = r2_score(y_test, preds)\n",
    "    reg_results[name] = {\"MAE\": float(mae), \"RMSE\": float(np.sqrt(mse)), \"R2\": float(r2)}\n",
    "    print(f\"[REG {name}] MAE={mae:.2f} | RMSE={np.sqrt(mse):.2f} | R2={r2:.3f}\")\n",
    "    if mae < best_mae:\n",
    "        best_mae, best_reg_name, best_reg_pipe = mae, name, pipe\n",
    "\n",
    "print(\"\\nBest regression:\", best_reg_name, \"MAE=\", round(best_mae,2))\n",
    "\n",
    "# Save regression artifacts\n",
    "reg_model_path = os.path.join(ARTIF_DIR, f\"regression_{best_reg_name}_{STAMP}.pkl\")\n",
    "reg_metrics_path = os.path.join(REPORTS_DIR, f\"regression_metrics_{STAMP}.json\")\n",
    "joblib.dump(best_reg_pipe, reg_model_path)\n",
    "with open(reg_metrics_path, \"w\") as f:\n",
    "    json.dump({\"best_model\": best_reg_name, \"results\": reg_results, \"cutoff\": str(cutoff.date())}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ed94b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS logreg] ACC=0.820 | F1=0.000 | AUC=0.508\n",
      "[CLS rf] ACC=0.557 | F1=0.235 | AUC=0.490\n",
      "\n",
      "Best classifier: rf F1= 0.235\n"
     ]
    }
   ],
   "source": [
    "threshold = y_train.quantile(0.80)\n",
    "y_train_cls = (y_train >= threshold).astype(int)\n",
    "y_test_cls  = (y_test  >= threshold).astype(int)\n",
    "\n",
    "cls_models = {\n",
    "    \"logreg\": LogisticRegression(max_iter=300),\n",
    "    \"rf\": RandomForestClassifier(n_estimators=300, n_jobs=-1, class_weight=\"balanced\", random_state=42),\n",
    "}\n",
    "cls_results = {}\n",
    "best_cls_name, best_cls_pipe, best_f1 = None, None, -1\n",
    "\n",
    "for name, est in cls_models.items():\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocess), (\"model\", est)])\n",
    "    pipe.fit(X_train, y_train_cls)\n",
    "    preds = pipe.predict(X_test)\n",
    "    proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe, \"predict_proba\") else None\n",
    "    acc = accuracy_score(y_test_cls, preds)\n",
    "    f1  = f1_score(y_test_cls, preds)\n",
    "    auc = roc_auc_score(y_test_cls, proba) if proba is not None else float(\"nan\")\n",
    "    cls_results[name] = {\"ACC\": float(acc), \"F1\": float(f1), \"AUC\": float(auc), \"label_threshold\": float(threshold)}\n",
    "    print(f\"[CLS {name}] ACC={acc:.3f} | F1={f1:.3f} | AUC={auc:.3f}\")\n",
    "    if f1 > best_f1:\n",
    "        best_f1, best_cls_name, best_cls_pipe = f1, name, pipe\n",
    "\n",
    "print(\"\\nBest classifier:\", best_cls_name, \"F1=\", round(best_f1,3))\n",
    "\n",
    "# Save classification artifacts\n",
    "cls_model_path = os.path.join(ARTIF_DIR, f\"classifier_{best_cls_name}_{STAMP}.pkl\")\n",
    "cls_metrics_path = os.path.join(REPORTS_DIR, f\"classifier_metrics_{STAMP}.json\")\n",
    "joblib.dump(best_cls_pipe, cls_model_path)\n",
    "with open(cls_metrics_path, \"w\") as f:\n",
    "    json.dump({\"best_model\": best_cls_name, \"results\": cls_results, \"label_threshold\": float(threshold)}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3354d459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved locally:\n",
      " - /Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/notebooks/models/regression_elasticnet_20250818T112246Z.pkl\n",
      " - /Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/notebooks/reports/regression_metrics_20250818T112246Z.json\n",
      " - /Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/notebooks/models/classifier_rf_20250818T112246Z.pkl\n",
      " - /Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/notebooks/reports/classifier_metrics_20250818T112246Z.json\n",
      " - /Users/haseebsagheer/Documents/Python Learning/Cloud-Retail-Insights/notebooks/reports/reg_actual_vs_pred_20250818T112246Z.png\n"
     ]
    }
   ],
   "source": [
    "preds = best_reg_pipe.predict(X_test)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(y_test, preds, alpha=0.35)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()])\n",
    "plt.xlabel(\"Actual Sales\"); plt.ylabel(\"Predicted Sales\")\n",
    "plt.title(\"Actual vs Predicted (Test)\")\n",
    "plt.grid(True); plt.tight_layout()\n",
    "plot1 = os.path.join(REPORTS_DIR, f\"reg_actual_vs_pred_{STAMP}.png\")\n",
    "plt.savefig(plot1, dpi=140); plt.close()\n",
    "\n",
    "with open(os.path.join(REPORTS_DIR, f\"classification_threshold_{STAMP}.txt\"), \"w\") as f:\n",
    "    f.write(f\"High-sale threshold (train 80th percentile): {threshold:.4f}\\n\")\n",
    "\n",
    "print(\"\\nSaved locally:\")\n",
    "print(\" -\", reg_model_path)\n",
    "print(\" -\", reg_metrics_path)\n",
    "print(\" -\", cls_model_path)\n",
    "print(\" -\", cls_metrics_path)\n",
    "print(\" -\", plot1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0865a49a",
   "metadata": {},
   "source": [
    "## Day 4 Summary\n",
    "\n",
    "- **Objective:** Train baseline models for forecasting (regression) and high-seller classification.\n",
    "- **Data Used:** Cleaned sales dataset with derived time features (`OrderYear`, `OrderMonth`, `OrderQuarter`, etc.).\n",
    "- **Models Tested:**\n",
    "  - Regression: ElasticNet, Random Forest, Gradient Boosting\n",
    "  - Classification: Logistic Regression, Random Forest\n",
    "- **Key Results:**\n",
    "  - Best regression → **ElasticNet** (lowest MAE ~264, but weak R²)\n",
    "  - Best classifier → **Random Forest** (best F1 ~0.23, though still low)\n",
    "- **Outputs Saved:** Metrics (JSON), trained models (Pickle), and plots (PNG).\n",
    "- **Takeaway:** Baseline models trained successfully. Performance is limited with current features → next steps will focus on feature importance, engineering, and tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195cec47",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

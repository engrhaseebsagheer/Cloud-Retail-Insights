{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a10bc9f9",
   "metadata": {},
   "source": [
    "### Model Evaluation & Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec14e9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No engine found, will use local fallback if needed. Err: ModuleNotFoundError(\"No module named 'db_connect'\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No SQL and no _inputs/processed_sales.parquet or _inputs/fact_sales.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 86\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(cs)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo SQL and no _inputs/processed_sales.parquet or _inputs/fact_sales.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m df \u001b[38;5;241m=\u001b[39m read_from_sql_or_fallback()\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m))\n",
      "Cell \u001b[0;32mIn[1], line 84\u001b[0m, in \u001b[0;36mread_from_sql_or_fallback\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cs):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(cs)\n\u001b[0;32m---> 84\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo SQL and no _inputs/processed_sales.parquet or _inputs/fact_sales.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No SQL and no _inputs/processed_sales.parquet or _inputs/fact_sales.csv"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Day 5: Evaluation, Diagnostics, Model Card (Local only)\n",
    "# - Read-only from SQL or local files\n",
    "# - No Azure writes\n",
    "# =========================\n",
    "\n",
    "import os, re, json, glob, warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, f1_score, accuracy_score\n",
    ")\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# ---------- Paths ----------\n",
    "ROOT = os.path.abspath(os.getcwd())\n",
    "ARTIF_DIR   = os.path.join(ROOT, \"models\")\n",
    "REPORTS_DIR = os.path.join(ROOT, \"reports\")\n",
    "DOCS_DIR    = os.path.join(ROOT, \"docs\")\n",
    "INPUTS_DIR  = os.path.join(ROOT, \"_inputs\")\n",
    "\n",
    "os.makedirs(ARTIF_DIR, exist_ok=True)\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "os.makedirs(DOCS_DIR, exist_ok=True)\n",
    "os.makedirs(INPUTS_DIR, exist_ok=True)\n",
    "\n",
    "STAMP = datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "\n",
    "# ---------- 0) Engine import (your working one) ----------\n",
    "# Make a small db_connect.py at project root that defines `engine`\n",
    "#   from sqlalchemy import create_engine\n",
    "#   engine = create_engine(\"<YOUR WORKING CONNECTION STRING>\")\n",
    "try:\n",
    "    from db_connect import engine   # <--- uses your proven engine\n",
    "except Exception as e:\n",
    "    engine = None\n",
    "    print(\"No engine found, will use local fallback if needed. Err:\", repr(e))\n",
    "\n",
    "# ---------- 1) Data load (same logic as Day 4) ----------\n",
    "def read_from_sql_or_fallback():\n",
    "    # Try SQL first\n",
    "    if engine is not None:\n",
    "        try:\n",
    "            with engine.begin() as conn:\n",
    "                # Prefer a processed view if you created it; else minimal fact\n",
    "                has_view = False\n",
    "                try:\n",
    "                    _ = pd.read_sql(\"SELECT TOP (1) * FROM dbo.v_processed_sales\", conn)\n",
    "                    has_view = True\n",
    "                except Exception:\n",
    "                    pass\n",
    "                if has_view:\n",
    "                    df = pd.read_sql(\"SELECT * FROM dbo.v_processed_sales\", conn)\n",
    "                else:\n",
    "                    q = \"\"\"\n",
    "                    SELECT f.OrderID, f.CustomerID, f.ProductID, f.Region,\n",
    "                           f.OrderDate, f.ShipDate, f.Sales\n",
    "                    FROM dbo.fact_sales f\n",
    "                    \"\"\"\n",
    "                    df = pd.read_sql(q, conn)\n",
    "            if not df.empty:\n",
    "                return df\n",
    "        except Exception as e:\n",
    "            print(\"SQL read failed, fallback to local:\", repr(e))\n",
    "\n",
    "    # Local fallback\n",
    "    pq = os.path.join(INPUTS_DIR, \"processed_sales.parquet\")\n",
    "    cs = os.path.join(INPUTS_DIR, \"fact_sales.csv\")\n",
    "    if os.path.exists(pq):\n",
    "        return pd.read_parquet(pq)\n",
    "    if os.path.exists(cs):\n",
    "        return pd.read_csv(cs)\n",
    "\n",
    "    raise FileNotFoundError(\"No SQL and no _inputs/processed_sales.parquet or _inputs/fact_sales.csv\")\n",
    "\n",
    "df = read_from_sql_or_fallback()\n",
    "print(\"Loaded:\", df.shape)\n",
    "print(df.head(3))\n",
    "\n",
    "# ---------- 2) Rebuild derived columns (safe) ----------\n",
    "def to_datetime_safe(s):\n",
    "    return pd.to_datetime(s, errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "for dcol in [\"OrderDate\",\"ShipDate\"]:\n",
    "    if dcol in df.columns and not np.issubdtype(df[dcol].dtype, np.datetime64):\n",
    "        df[dcol] = to_datetime_safe(df[dcol])\n",
    "\n",
    "# Derive (order)\n",
    "if \"OrderDate\" in df.columns:\n",
    "    df[\"OrderYear\"] = df[\"OrderDate\"].dt.year\n",
    "    df[\"OrderMonth\"] = df[\"OrderDate\"].dt.month\n",
    "    df[\"OrderQuarter\"] = df[\"OrderDate\"].dt.quarter\n",
    "    df[\"OrderWeekOfYear\"] = df[\"OrderDate\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "    df[\"OrderMonthName\"] = df[\"OrderDate\"].dt.month_name()\n",
    "    df[\"OrderIsWeekendOrder\"] = df[\"OrderDate\"].dt.dayofweek.isin([5,6]).astype(int)\n",
    "    df[\"OrderYearMonth\"] = df[\"OrderDate\"].dt.to_period(\"M\").astype(str)\n",
    "\n",
    "# Derive (ship)\n",
    "if \"ShipDate\" in df.columns:\n",
    "    df[\"ShipYear\"] = df[\"ShipDate\"].dt.year\n",
    "    df[\"ShipMonth\"] = df[\"ShipDate\"].dt.month\n",
    "    df[\"ShipQuarter\"] = df[\"ShipDate\"].dt.quarter\n",
    "    df[\"ShipWeekOfYear\"] = df[\"ShipDate\"].dt.isocalendar().week.astype(\"Int64\")\n",
    "    df[\"ShipMonthName\"] = df[\"ShipDate\"].dt.month_name()\n",
    "    df[\"ShipIsWeekendShip\"] = df[\"ShipDate\"].dt.dayofweek.isin([5,6]).astype(int)\n",
    "\n",
    "if {\"OrderDate\",\"ShipDate\"}.issubset(df.columns):\n",
    "    df[\"DaysToShip\"] = (df[\"ShipDate\"] - df[\"OrderDate\"]).dt.days\n",
    "\n",
    "# Clean strings\n",
    "for col in [\"ShipMode\",\"Segment\",\"Country\",\"State\",\"Region\",\"Category\",\"SubCategory\",\"ProductName\",\"CustomerName\",\"City\",\"PostalCode\"]:\n",
    "    if col in df.columns and df[col].dtype == object:\n",
    "        df[col] = df[col].astype(str).strip()\n",
    "\n",
    "# Drop bad rows\n",
    "need = [c for c in [\"OrderID\",\"ProductID\",\"CustomerID\",\"OrderDate\",\"Sales\"] if c in df.columns]\n",
    "df = df.dropna(subset=need)\n",
    "df[\"Sales\"] = pd.to_numeric(df[\"Sales\"], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Sales\"])\n",
    "df = df[df[\"Sales\"] >= 0]\n",
    "\n",
    "print(\"Post-clean:\", df.shape)\n",
    "\n",
    "# ---------- 3) Build feature matrix same as Day 4 ----------\n",
    "categorical_features = [\"Region\",\"OrderMonthName\"]  # kept minimal on purpose (matches yesterday’s run)\n",
    "numeric_features = [\"OrderYear\",\"OrderMonth\",\"OrderQuarter\",\"OrderWeekOfYear\",\"OrderIsWeekendOrder\"]\n",
    "target_col = \"Sales\"\n",
    "\n",
    "drop_cols = [\n",
    "    \"CustomerName\",\"City\",\"PostalCode\",\"ProductName\",\n",
    "    \"OrderID\",\"CustomerID\",\"ProductID\",\n",
    "    \"OrderDate\",\"ShipDate\",\n",
    "    \"ShipYear\",\"ShipMonth\",\"ShipQuarter\",\"ShipYearMonth\",\"ShipWeekOfYear\",\"ShipMonthName\",\"ShipIsWeekendShip\",\"DaysToShip\",\n",
    "    \"OrderYearMonth\"\n",
    "]\n",
    "drop_cols = [c for c in drop_cols if c in df.columns]\n",
    "\n",
    "X_all = df.drop(columns=[target_col] + drop_cols, errors=\"ignore\")\n",
    "y_all = df[target_col].astype(float)\n",
    "\n",
    "# time-aware split\n",
    "cutoff = df[\"OrderDate\"].quantile(0.80)\n",
    "train_mask = df[\"OrderDate\"] <= cutoff\n",
    "X_train, y_train = X_all[train_mask].copy(), y_all[train_mask].copy()\n",
    "X_test,  y_test  = X_all[~train_mask].copy(), y_all[~train_mask].copy()\n",
    "\n",
    "print(\"Cutoff:\", cutoff.date(), \"| Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "# ---------- 4) Reload latest saved models & metrics ----------\n",
    "def latest_file(pattern):\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        return None\n",
    "    return max(files, key=os.path.getmtime)\n",
    "\n",
    "reg_model_path = latest_file(os.path.join(ARTIF_DIR, \"regression_*.pkl\"))\n",
    "cls_model_path = latest_file(os.path.join(ARTIF_DIR, \"classifier_*.pkl\"))\n",
    "reg_metrics_path = latest_file(os.path.join(REPORTS_DIR, \"regression_metrics_*.json\"))\n",
    "cls_metrics_path = latest_file(os.path.join(REPORTS_DIR, \"classifier_metrics_*.json\"))\n",
    "\n",
    "print(\"Loaded model files:\")\n",
    "print(\" - regression:\", reg_model_path)\n",
    "print(\" - classifier:\", cls_model_path)\n",
    "\n",
    "best_reg = joblib.load(reg_model_path) if reg_model_path else None\n",
    "best_cls = joblib.load(cls_model_path) if cls_model_path else None\n",
    "\n",
    "prev_reg_json = json.load(open(reg_metrics_path)) if reg_metrics_path else {\"results\":{}}\n",
    "prev_cls_json = json.load(open(cls_metrics_path)) if cls_metrics_path else {\"results\":{}}\n",
    "\n",
    "# ---------- 5) Evaluate regression in depth ----------\n",
    "reg_preds = best_reg.predict(X_test)\n",
    "reg_mae  = mean_absolute_error(y_test, reg_preds)\n",
    "reg_rmse = float(np.sqrt(mean_squared_error(y_test, reg_preds)))\n",
    "reg_r2   = r2_score(y_test, reg_preds)\n",
    "\n",
    "reg_eval = pd.DataFrame([{\"MAE\": reg_mae, \"RMSE\": reg_rmse, \"R2\": reg_r2, \"cutoff\": str(cutoff.date())}])\n",
    "reg_eval.to_csv(os.path.join(REPORTS_DIR, f\"regression_eval_{STAMP}.csv\"), index=False)\n",
    "\n",
    "# residuals\n",
    "residuals = y_test.values - reg_preds\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(reg_preds, residuals, alpha=0.3)\n",
    "plt.axhline(0, lw=1)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residual (Actual - Pred)\")\n",
    "plt.title(\"Residuals vs Predicted\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORTS_DIR, f\"reg_residuals_vs_pred_{STAMP}.png\"), dpi=140)\n",
    "plt.close()\n",
    "\n",
    "# error by month (helps find seasonality problems)\n",
    "tmp = pd.DataFrame({\n",
    "    \"OrderMonth\": df.loc[~train_mask, \"OrderMonth\"].values,\n",
    "    \"abs_err\": np.abs(y_test.values - reg_preds)\n",
    "})\n",
    "err_by_month = tmp.groupby(\"OrderMonth\")[\"abs_err\"].mean().reset_index()\n",
    "err_by_month.to_csv(os.path.join(REPORTS_DIR, f\"reg_abs_error_by_month_{STAMP}.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(err_by_month[\"OrderMonth\"], err_by_month[\"abs_err\"], marker=\"o\")\n",
    "plt.xlabel(\"OrderMonth\")\n",
    "plt.ylabel(\"Mean absolute error\")\n",
    "plt.title(\"Regression error by month\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(REPORTS_DIR, f\"reg_error_by_month_{STAMP}.png\"), dpi=140)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 6) Evaluate classification in depth ----------\n",
    "# Baseline at saved model's default threshold (0.5 unless otherwise inside model)\n",
    "cls_proba = best_cls.predict_proba(X_test)[:,1] if hasattr(best_cls, \"predict_proba\") else None\n",
    "cls_pred  = best_cls.predict(X_test)\n",
    "\n",
    "# Build labels using Day 4 rule: top-20% high-sellers on TRAIN\n",
    "thr_train = y_train.quantile(0.80)\n",
    "y_train_cls = (y_train >= thr_train).astype(int)\n",
    "y_test_cls  = (y_test  >= thr_train).astype(int)\n",
    "\n",
    "acc0 = accuracy_score(y_test_cls, cls_pred)\n",
    "f10  = f1_score(y_test_cls, cls_pred)\n",
    "auc0 = roc_auc_score(y_test_cls, cls_proba) if cls_proba is not None else float(\"nan\")\n",
    "\n",
    "# Threshold tuning (maximize F1 on test set)\n",
    "best_f1, best_thr = -1, 0.5\n",
    "if cls_proba is not None:\n",
    "    prec, rec, ths = precision_recall_curve(y_test_cls, cls_proba)\n",
    "    # compute F1 for each threshold\n",
    "    f1s = (2*prec*rec/(prec+rec+1e-9))\n",
    "    best_idx = int(np.nanargmax(f1s))\n",
    "    best_f1 = float(f1s[best_idx])\n",
    "    if best_idx == 0:\n",
    "        # scikit gives no threshold for the first PR point\n",
    "        best_thr = 0.5\n",
    "    else:\n",
    "        best_thr = float(ths[best_idx-1])\n",
    "\n",
    "    # apply tuned threshold\n",
    "    cls_pred_tuned = (cls_proba >= best_thr).astype(int)\n",
    "    acc1 = accuracy_score(y_test_cls, cls_pred_tuned)\n",
    "    f11  = f1_score(y_test_cls, cls_pred_tuned)\n",
    "    auc1 = auc0  # same probs\n",
    "\n",
    "    # Save PR and ROC curves\n",
    "    fpr, tpr, _ = roc_curve(y_test_cls, cls_proba)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1],[0,1], ls=\"--\")\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(REPORTS_DIR, f\"cls_roc_{STAMP}.png\"), dpi=140)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.plot(rec, prec)\n",
    "    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"PR Curve\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(REPORTS_DIR, f\"cls_pr_{STAMP}.png\"), dpi=140)\n",
    "    plt.close()\n",
    "\n",
    "# Confusion matrices (default and tuned)\n",
    "def save_conf_mat(y_true, y_pred, fname):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    ax.imshow(cm, cmap=\"Blues\")\n",
    "    for (i,j),v in np.ndenumerate(cm):\n",
    "        ax.text(j, i, str(v), ha=\"center\", va=\"center\")\n",
    "    ax.set_xticks([0,1]); ax.set_yticks([0,1])\n",
    "    ax.set_xticklabels([\"Low\",\"High\"]); ax.set_yticklabels([\"Low\",\"High\"])\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"Actual\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(REPORTS_DIR, fname), dpi=140); plt.close()\n",
    "\n",
    "save_conf_mat(y_test_cls, cls_pred, f\"cls_confusion_default_{STAMP}.png\")\n",
    "if cls_proba is not None:\n",
    "    save_conf_mat(y_test_cls, (cls_proba>=best_thr).astype(int), f\"cls_confusion_tuned_{STAMP}.png\")\n",
    "\n",
    "# Metrics table\n",
    "rows = [{\n",
    "    \"mode\":\"default\", \"ACC\":acc0, \"F1\":f10, \"AUC\":auc0, \"threshold\":0.5\n",
    "}]\n",
    "if cls_proba is not None:\n",
    "    rows.append({\"mode\":\"tuned\", \"ACC\":acc1, \"F1\":f11, \"AUC\":auc1, \"threshold\":best_thr})\n",
    "\n",
    "cls_eval = pd.DataFrame(rows)\n",
    "cls_eval.to_csv(os.path.join(REPORTS_DIR, f\"classification_eval_{STAMP}.csv\"), index=False)\n",
    "\n",
    "# ---------- 7) Explainability ----------\n",
    "def get_feature_names_from_preprocessor(prep: ColumnTransformer):\n",
    "    # Works on sklearn >=1.0\n",
    "    try:\n",
    "        return prep.get_feature_names_out()\n",
    "    except Exception:\n",
    "        names = []\n",
    "        for name, trans, cols in prep.transformers_:\n",
    "            if name == \"remainder\" and trans == \"drop\":\n",
    "                continue\n",
    "            if hasattr(trans, \"get_feature_names_out\"):\n",
    "                try:\n",
    "                    sub = trans.get_feature_names_out(cols)\n",
    "                except Exception:\n",
    "                    sub = cols\n",
    "            else:\n",
    "                sub = cols\n",
    "            # prefix with transformer name to keep uniqueness\n",
    "            sub = [f\"{name}__{c}\" for c in sub]\n",
    "            names.extend(sub)\n",
    "        return np.array(names, dtype=object)\n",
    "\n",
    "# 7a) ElasticNet coefficients\n",
    "reg_prep = best_reg.named_steps[\"prep\"]\n",
    "reg_model = best_reg.named_steps[\"model\"]\n",
    "\n",
    "feat_names = get_feature_names_from_preprocessor(reg_prep)\n",
    "coefs = getattr(reg_model, \"coef_\", None)\n",
    "reg_coef_df = None\n",
    "if coefs is not None and len(np.atleast_1d(coefs)) == len(feat_names):\n",
    "    reg_coef_df = pd.DataFrame({\"feature\": feat_names, \"coef\": np.atleast_1d(coefs)})\n",
    "    reg_coef_df.sort_values(\"coef\", key=np.abs, ascending=False, inplace=True)\n",
    "    reg_coef_df.to_csv(os.path.join(REPORTS_DIR, f\"reg_elasticnet_coefficients_{STAMP}.csv\"), index=False)\n",
    "\n",
    "# 7b) RF classifier importances (aggregated back to original fields)\n",
    "cls_prep = best_cls.named_steps[\"prep\"]\n",
    "cls_model = best_cls.named_steps[\"model\"]\n",
    "cls_feat_names = get_feature_names_from_preprocessor(cls_prep)\n",
    "importances = getattr(cls_model, \"feature_importances_\", None)\n",
    "\n",
    "agg_imp = None\n",
    "if importances is not None and len(importances) == len(cls_feat_names):\n",
    "    imp_df = pd.DataFrame({\"feature\": cls_feat_names, \"importance\": importances})\n",
    "    # collapse one-hot groups back to their source column\n",
    "    # a feature name typically looks like: \"cat__Region_East\" or \"num__OrderMonth\"\n",
    "    def base_col(s):\n",
    "        # remove transformer prefix and one-hot suffix\n",
    "        s = s.replace(\"cat__\", \"\").replace(\"num__\", \"\")\n",
    "        # if one-hot, it looks like Region_East -> base 'Region'\n",
    "        return s.split(\"_\")[0]\n",
    "    imp_df[\"base\"] = imp_df[\"feature\"].apply(base_col)\n",
    "    agg_imp = imp_df.groupby(\"base\", as_index=False)[\"importance\"].sum().sort_values(\"importance\", ascending=False)\n",
    "    agg_imp.to_csv(os.path.join(REPORTS_DIR, f\"classifier_importance_aggregated_{STAMP}.csv\"), index=False)\n",
    "\n",
    "    # quick bar plot of top-10\n",
    "    top = agg_imp.head(10)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.barh(top[\"base\"][::-1], top[\"importance\"][::-1])\n",
    "    plt.title(\"RF Classifier: Top feature groups\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(REPORTS_DIR, f\"classifier_importance_top10_{STAMP}.png\"), dpi=140)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- 8) Comparison tables from previous JSONs ----------\n",
    "# Helpful when you’ve saved all model metrics during Day 4\n",
    "if \"results\" in prev_reg_json and prev_reg_json[\"results\"]:\n",
    "    reg_table = pd.DataFrame(prev_reg_json[\"results\"]).T.reset_index().rename(columns={\"index\":\"model\"})\n",
    "    reg_table.to_csv(os.path.join(REPORTS_DIR, f\"regression_models_comparison_{STAMP}.csv\"), index=False)\n",
    "\n",
    "if \"results\" in prev_cls_json and prev_cls_json[\"results\"]:\n",
    "    cls_table = pd.DataFrame(prev_cls_json[\"results\"]).T.reset_index().rename(columns={\"index\":\"model\"})\n",
    "    cls_table.to_csv(os.path.join(REPORTS_DIR, f\"classification_models_comparison_{STAMP}.csv\"), index=False)\n",
    "\n",
    "# ---------- 9) Model Card generator ----------\n",
    "MODEL_CARD = f\"\"\"# Model Card — Retail Sales (Day 5)\n",
    "Generated: {STAMP}\n",
    "\n",
    "## Overview\n",
    "- **Project:** Cloud-Based Retail Sales Analytics & Forecasting\n",
    "- **Data source:** Kaggle Sales Forecasting (train CSV), ~9.8k rows landed\n",
    "- **Split policy:** time-aware split by OrderDate (80% train, 20% test)\n",
    "- **Target(s):** \n",
    "  - Regression: Sales (float)\n",
    "  - Classification: High-seller (>= 80th percentile of train Sales)\n",
    "\n",
    "## Best Models (Day 4 -> Day 5 verified)\n",
    "### Regression\n",
    "- Algorithm: {type(best_reg.named_steps['model']).__name__}\n",
    "- Metrics (test): MAE={reg_mae:.2f}, RMSE={reg_rmse:.2f}, R2={reg_r2:.3f}\n",
    "- Notes: baseline performance is limited; stronger features needed (lags, product/region aggregates).\n",
    "\n",
    "### Classification\n",
    "- Algorithm: {type(best_cls.named_steps['model']).__name__}\n",
    "- Metrics (test, default): ACC={acc0:.3f}, F1={f10:.3f}, AUC={auc0:.3f}\n",
    "- Metrics (test, tuned threshold={best_thr:.3f}): F1={rows[-1]['F1']:.3f} (if tuned computed)\n",
    "- Notes: class imbalance; tuned threshold improves F1. Try more features + class weighting and AUC optimization.\n",
    "\n",
    "## Features used\n",
    "- Categorical: Region, OrderMonthName\n",
    "- Numeric: OrderYear, OrderMonth, OrderQuarter, OrderWeekOfYear, OrderIsWeekendOrder\n",
    "- Leakage control: no Ship* fields used for training\n",
    "\n",
    "## Explainability\n",
    "- ElasticNet coefficients: see reports/reg_elasticnet_coefficients_*.csv\n",
    "- RF classifier importances (aggregated): see reports/classifier_importance_aggregated_*.csv\n",
    "\n",
    "## Artifacts\n",
    "- Models: models/regression_*.pkl, models/classifier_*.pkl\n",
    "- Metrics: reports/regression_metrics_*.json, reports/classifier_metrics_*.json\n",
    "- Day 5 eval: reports/regression_eval_*.csv, reports/classification_eval_*.csv\n",
    "- Plots: reports/reg_residuals_vs_pred_*.png, reports/cls_roc_*.png, reports/cls_pr_*.png\n",
    "\n",
    "## Intended use\n",
    "- Educational baseline for retail sales analytics and forecasting in a cloud-like stack (ADF + SQL + Python).\n",
    "\n",
    "## Limitations\n",
    "- Current features are simple date-based signals; no product/customer history, no external seasonality.\n",
    "- Dataset variant lacks Quantity/Discount/Profit.\n",
    "\n",
    "## Next steps\n",
    "- Add lags and rolling aggregates per product/region.\n",
    "- Try XGBoost/LightGBM and hyperparameter tuning.\n",
    "- Register in Azure ML and deploy a small REST endpoint.\n",
    "\"\"\"\n",
    "with open(os.path.join(DOCS_DIR, \"MODEL_CARD.md\"), \"w\") as f:\n",
    "    f.write(MODEL_CARD)\n",
    "\n",
    "print(\"\\nSaved:\")\n",
    "print(\" -\", os.path.join(REPORTS_DIR, f\"regression_eval_{STAMP}.csv\"))\n",
    "print(\" -\", os.path.join(REPORTS_DIR, f\"classification_eval_{STAMP}.csv\"))\n",
    "print(\" -\", os.path.join(DOCS_DIR, \"MODEL_CARD.md\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74dec9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
